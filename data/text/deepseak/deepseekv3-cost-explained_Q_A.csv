user_input,reference_contexts,reference,synthesizer_name
What makes Deepseek V3 a significant advancement in AI?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek V3 is significant due to its efficient training methods, including a Mixture-of-Experts architecture that activates only 37B parameters for each token out of 671B, reducing compute requirements. It also employs FP8 mixed precision training to cut memory usage by up to 50% and has a custom training framework called HAI-LLM that optimizes pipeline parallelism and memory usage.",single_hop_specifc_query_synthesizer
Who is Visith Kumarapperuma and what is his contribution to AI?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Visith Kumarapperuma is the author of the article discussing Deepseek V3, a significant advancement in AI. He highlights how Deepseek's latest reasoning model, Deepseek r1, has shown competitive performance while being more cost-effective in training and inference. Kumarapperuma emphasizes Deepseek's innovative approach of improving algorithms rather than hardware, which has made a substantial impact in the AI industry.",single_hop_specifc_query_synthesizer
Why is ChatGPT considered less impactful compared to Deepseek's AI Assistant in the current AI landscape?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","ChatGPT is considered less impactful because Deepseek's AI Assistant has overtaken it to become the most downloaded free app on the U.S. App Store, indicating a significant shift in user preference and market dynamics.",single_hop_specifc_query_synthesizer
How has Deepseek's AI Assistant impacted the U.S. App Store and what implications does this have for major U.S. tech companies?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek's AI Assistant has overtaken ChatGPT to become the most downloaded free app on the U.S. App Store. This significant achievement has raised market concerns regarding A.I. investments in major U.S. tech companies, impacting the share prices of firms including Nvidia.",single_hop_specifc_query_synthesizer
What Deepseek do in AI?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek is causing a stir in the AI space with its latest reasoning model, Deepseek r1, which shows better or equal performance to competitors while achieving this with a fraction of the training and inference cost. Their AI Assistant has overtaken ChatGPT to become the most downloaded free app on the U.S. App Store, impacting market concerns about A.I. investments in major U.S. tech companies.",single_hop_specifc_query_synthesizer
What are the key innovations of Deepseek r1 that contribute to its efficiency in AI training?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek r1 achieves efficiency in AI training through several key innovations: it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B, which significantly reduces compute requirements. The model utilizes Multi-head Latent Attention (MLA) to compress the Key-Value cache, thereby reducing memory usage. Additionally, it implements FP8 mixed precision training, which reduces memory usage and accelerates training compared to higher precision formats, achieving a reduced memory footprint by up to 50%. Deepseek also pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture, improving performance without traditional drawbacks. Lastly, they developed a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations.",single_hop_specifc_query_synthesizer
What innovations did Visith Kumarapperuma and Deepseek implement in their AI model to achieve significant efficiency improvements?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Visith Kumarapperuma and Deepseek implemented several innovations in their AI model, Deepseek V3, to achieve significant efficiency improvements. They utilized a Mixture-of-Experts (MoE) architecture, where only 37B parameters are activated for each token out of a total of 671B, significantly reducing compute requirements. They also employed FP8 mixed precision training, which reduced memory usage and accelerated training compared to higher precision formats, achieving a memory footprint reduction of up to 50%. Additionally, they developed a custom training framework called HAI-LLM, which included optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies without the drawbacks of traditional methods. These innovations collectively made training 45 times more efficient.",single_hop_specifc_query_synthesizer
What is MoE in the context of Deepseek's model?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","MoE stands for Mixture-of-Experts, which is an architecture used in Deepseek's model. It allows only a subset of parameters to be activated for each token, significantly reducing compute requirements compared to dense models.",single_hop_specifc_query_synthesizer
"In what ways does the Deepseek r1 model demonstrate advancements in AI compared to its competitors, particularly in terms of efficiency and performance?","['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","The Deepseek r1 model showcases significant advancements in AI by achieving better or equal performance to its competitors while utilizing a fraction of the training and inference costs. It employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B, which greatly reduces compute requirements. Additionally, Deepseek implemented FP8 mixed precision training, reducing memory usage and accelerating training by up to 50% compared to traditional formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. These innovations collectively contribute to making Deepseek r1 45 times more efficient in training, allowing it to compress key value indices and double inference speeds.",single_hop_specifc_query_synthesizer
Wht is the significance of the U.S. App Store in the context of Deepseek's AI Assistant?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","The U.S. App Store is significant in the context of Deepseek's AI Assistant because it became the most downloaded free app on the U.S. App Store, indicating a major impact on the market and raising concerns about A.I. investments among major U.S. tech companies.",single_hop_specifc_query_synthesizer
How has Deepseek impacted the field of AI with its latest model?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek has significantly impacted the field of AI with its latest model, Deepseek r1, which demonstrates better or equal performance compared to competitors while achieving this with a fraction of the training and inference cost. The company focused on improving algorithms rather than hardware, making training 45 times more efficient through various innovations such as using 8-bit instead of 32-bit to save memory, compressing key value indices for a 93% compression ratio, and employing multi-token prediction to double inference speeds. Additionally, the model architecture utilizes a Mixture-of-Experts (MoE) approach, which reduces compute requirements by activating only a subset of parameters for each token. These advancements have led to Deepseek's AI Assistant becoming the most downloaded free app on the U.S. App Store, raising market concerns about AI investments in major U.S. tech companies.",single_hop_specifc_query_synthesizer
Wut is the MOE model in Deepseek V3?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","The MOE model in Deepseek V3 decomposes a big model into small models that can run on consumer-grade hardware. It employs a Mixture-of-Experts architecture, where only 37B parameters fire for each token out of the total 671B, significantly reducing compute requirements compared to dense models.",single_hop_specifc_query_synthesizer
Can you explain how the MoE architecture contributes to the efficiency of Deepseek V3 in training AI models?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","The MoE model in Deepseek V3 decomposes a large model into smaller models that can run on consumer-grade hardware. It employs a Mixture-of-Experts architecture, where only 37 billion parameters are activated for each token out of a total of 671 billion. This sparse activation significantly reduces compute requirements compared to dense models, contributing to the overall efficiency of training.",single_hop_specifc_query_synthesizer
Can you explain the significance of Deepseek r1 in the context of AI advancements and its impact on the industry?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek r1 is significant in the AI landscape as it demonstrates better or equal performance compared to competitors while achieving this with a fraction of the training and inference cost. The model's efficiency stems from its innovative approach, focusing on algorithm improvements rather than hardware enhancements. Deepseek's AI Assistant has even surpassed ChatGPT in downloads on the U.S. App Store, raising concerns among major U.S. tech companies about their AI investments. The model employs a Mixture-of-Experts architecture, which reduces compute requirements significantly, and utilizes FP8 mixed precision training to lower memory usage and accelerate training. These advancements have made Deepseek a disruptive force in the AI industry.",single_hop_specifc_query_synthesizer
In what ways has Deepseek V3 revolutionized AI training efficiency compared to traditional models?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek V3 has revolutionized AI training efficiency through several innovative approaches. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37 billion parameters for each token out of a total of 671 billion, which significantly reduces compute requirements. Additionally, the model utilizes Multi-head Latent Attention (MLA) to compress the Key-Value cache, further reducing memory usage. Secondly, Deepseek implemented an FP8 mixed precision training framework, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. Furthermore, they pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture, enhancing performance without the drawbacks of traditional methods. Lastly, the custom training framework called HAI-LLM includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and efficient cross-node communication kernels, maximizing network bandwidth utilization and minimizing costly tensor parallelism.",single_hop_specifc_query_synthesizer
"How has Nvidia contributed to the advancements in AI models, particularly in the context of Deepseek's training efficiency?","['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Nvidia has played a significant role in the advancements of AI models, particularly through its hardware, such as the H800 GPUs used by Deepseek. Deepseek trained its model using a data center of approximately 2,000 Nvidia H800 GPUs over a duration of two months, with the final training run costing around $5.5 million for GPU rental hours. This investment in Nvidia's technology has enabled Deepseek to achieve remarkable training efficiency, making their model 45 times more efficient by utilizing techniques such as 8-bit precision instead of 32-bit, achieving 93% compression ratios for key value indices, and employing a Mixture-of-Experts architecture that reduces compute requirements significantly.",single_hop_specifc_query_synthesizer
What makes Deepseek V3 a significant advancement in AI technology compared to other models?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek V3 is significant due to its innovative approach that focuses on improving algorithms rather than just hardware. It achieved 45 times more efficient training by using 8-bit instead of 32-bit to save memory, compressing key value indices with a 93% compression ratio, and employing multi-token prediction to double inference speeds. The model architecture utilizes a Mixture-of-Experts (MoE) design, activating only 37B parameters for each token out of 671B total, which reduces compute requirements. Additionally, it implements FP8 mixed precision training to cut memory usage by up to 50% and features a custom training framework called HAI-LLM with optimizations for efficient pipeline parallelism and memory management.",single_hop_specifc_query_synthesizer
How does FP8 mixed precision training contribute to the efficiency of Deepseek V3 in AI model development?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","FP8 mixed precision training implemented by Deepseek V3 reduces memory usage and accelerates training compared to higher precision formats. It achieves a reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats, allowing for more efficient training while maintaining accuracy through fine-grained quantisation strategies and increased accumulation precision.",single_hop_specifc_query_synthesizer
How does FP8 contribute to the efficiency of Deepseek's training process?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","FP8 mixed precision training reduces memory usage and accelerates training compared to higher precision formats, achieving a reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats.",single_hop_specifc_query_synthesizer
How does Deepseek's AI Assistant compare to ChatGPT in terms of app downloads?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']",Deepseek’s AI Assistant has overtaken ChatGPT to become the most downloaded free app on the U.S. App Store.,single_hop_specifc_query_synthesizer
Why Deepseek V3 become most downloaded free app on U.S. App Store?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store due to its advanced reasoning model, Deepseek r1, which shows better or equal performance to competitors while achieving this with a fraction of the training and inference cost.",single_hop_specifc_query_synthesizer
How does FP8 mixed precision training contribute to the efficiency of Deepseek V3 in terms of memory usage and training speed?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","FP8 mixed precision training implemented by Deepseek V3 reduces memory usage and accelerates training compared to higher precision formats. It achieves a reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats, allowing for more efficient training while maintaining accuracy through fine-grained quantisation strategies and increased accumulation precision.",single_hop_specifc_query_synthesizer
Why Deepseek is important in A.I. field?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek is important in the A.I. field because it has shown better or equal performance to competitors with a fraction of the training and inference cost. Its approach focuses on improving algorithms rather than just hardware, making training more efficient and impactful in the industry.",single_hop_specifc_query_synthesizer
What innovations did Visith Kumarapperuma's Deepseek V3 introduce to improve AI model training efficiency?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","Deepseek V3 introduced several innovations to improve AI model training efficiency, including the use of 8-bit instead of 32-bit to save memory, achieving 93% compression ratios for key value indices, and employing multi-token prediction to double inference speeds. The model architecture utilizes a Mixture-of-Experts (MoE) approach, activating only 37B parameters for each token out of a total of 671B, which significantly reduces compute requirements. Additionally, they implemented FP8 mixed precision training to reduce memory usage by up to 50% compared to traditional formats and developed a custom training framework called HAI-LLM with optimisations for efficient pipeline parallelism and memory management.",single_hop_specifc_query_synthesizer
What is the role of FP8 in Deepseek's training process?,"['<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##']","FP8 mixed precision training reduces memory usage and accelerates training compared to higher precision formats, achieving a reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats.",single_hop_specifc_query_synthesizer
What are the main differences between Deepseek v3 and GPT-4 in terms of performance and training costs?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 excels at reasoning and math, surpassing GPT-4, while for writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. In terms of training costs, Deepseek v3 was trained on 14.8 trillion high-quality data, taking 2,788,000 GPU hours at a cost of around $5.576 million, which is significantly lower than the training costs associated with models like Llama 3.1.",single_hop_specifc_query_synthesizer
What is the significance of MOE in the context of the Deepseek v3 model's architecture and performance?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","MOE, or Mixture of Agents, is significant in the Deepseek v3 model's architecture as it allows for a structure with 671 billion parameters, of which 37 billion are active parameters per token. This architecture contributes to Deepseek's success in reasoning and math, enabling it to surpass models like GPT-4 and Claude 3.5 Sonnet. The use of MOE architecture, along with breakthrough engineering techniques such as FP8 mixed precision training, plays a crucial role in optimizing the model's performance.",single_hop_specifc_query_synthesizer
How many GPU hours did the H800 contribute to training the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","During the pre-training stage, training DeepSeek-V3 on each trillion tokens requires only 180K H800 GPU hours. The overall pre-training took a total of 2,664K GPU hours, completed in less than two months using a cluster of 2,048 H800 GPUs.",single_hop_specifc_query_synthesizer
What role does the HAI-LLM framework play in the performance of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The HAI-LLM framework is a custom development that contributes to the breakthrough engineering of Deepseek's flagship model v3, which showcases an architecture with a 671B parameter MOE (Mixture of Agents) and excels at reasoning and math, surpassing models like GPT-4 and Claude 3.5 Sonnet.",single_hop_specifc_query_synthesizer
What is MOE in the context of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","MOE stands for Mixture of Agents, which is an architecture used in the Deepseek v3 model that features a total of 671 billion parameters, with 37 billion active parameters per token.",single_hop_specifc_query_synthesizer
In what ways does Claude 3.5 Sonnet compare to the Deepseek v3 model in terms of performance for writing and coding tasks?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead over the Deepseek v3 model, which excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet.",single_hop_specifc_query_synthesizer
What is FP8 in the context of Deepseek v3 model training?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","FP8 refers to the mixed precision training implemented in the Deepseek v3 model, which utilizes FP8 precision to optimize the training process.",single_hop_specifc_query_synthesizer
How does Claude 3.5 Sonnet compare to Deepseek v3 in terms of writing and coding tasks?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead over Deepseek v3.",single_hop_specifc_query_synthesizer
How much GPU hours did the Llama 403b model require for training?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Llama 403b was trained on 30,840,000 GPU hours.",single_hop_specifc_query_synthesizer
How does the MOE architecture contribute to the efficiency and performance of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The MOE (Mixture of Agents) architecture in the Deepseek v3 model allows for a structure that utilizes 671 billion parameters with 37 billion active parameters per token. This architecture is a key factor in the model's efficiency and performance, as it enables the model to excel at reasoning and math, surpassing competitors like GPT-4 and Claude 3.5 Sonnet. The implementation of MOE, along with FP8 mixed precision training and a custom HAI-LLM framework, contributes to the model's breakthrough engineering, allowing it to achieve high performance while managing a large number of parameters effectively.",single_hop_specifc_query_synthesizer
What are the key features of Deepseek v3 that contribute to its performance?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) and 37B active parameters per token. Its success stems from breakthrough engineering, including the use of MoE architecture, FP8 mixed precision training, and a custom HAI-LLM framework. Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet.",single_hop_specifc_query_synthesizer
How does the HAI-LLM framework contribute to the efficiency of the Deepseek v3 model's training process?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The HAI-LLM framework is a custom development that plays a crucial role in the efficiency of the Deepseek v3 model's training process. It is part of the model's architecture, which includes a 671B parameter Mixture of Agents (MOE) setup with 37B active parameters per token. This framework, combined with breakthrough engineering techniques such as FP8 mixed precision training, allows Deepseek to excel at reasoning and math, surpassing other models like GPT-4 and Claude 3.5 Sonnet. The efficient training process is further evidenced by the reported total training cost of approximately $5.576 million, achieved through the utilization of 2,788,000 GPU hours on the Nvidia h800s cluster.",single_hop_specifc_query_synthesizer
How much GPU hours did Llama 3.1 reportedly require for training?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']",Llama 3.1 reportedly required 30.84 million GPU hours in practice.,single_hop_specifc_query_synthesizer
How does Deepseek v3 compare to GPT-4 in terms of reasoning and math capabilities?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet.",single_hop_specifc_query_synthesizer
What is the role of FP8 in the training of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","FP8 is used in the Deepseek v3 model to achieve mixed precision training, which is part of the breakthrough engineering that contributes to the model's success.",single_hop_specifc_query_synthesizer
What is the significance of the HAI-LLM framework in the context of Deepseek v3 model's architecture and training costs?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The HAI-LLM framework is significant in the context of Deepseek v3 model's architecture as it is part of the breakthrough engineering that enables the model to excel at reasoning and math, surpassing other models like GPT-4 and Claude 3.5 Sonnet. The framework, along with the MoE architecture and FP8 mixed precision training, contributes to the model's efficiency and effectiveness, allowing it to be trained on 14.8 trillion high-quality data tokens at a cost of approximately $5.576 million, which is notably lower than other models with similar capabilities.",single_hop_specifc_query_synthesizer
How does the training cost of Llama 3.1 compare to that of Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The training cost of Llama 3.1 is significantly higher than that of the Deepseek v3 model. Llama 3.1, which has 405B parameters and was trained on 15 trillion tokens, reportedly required 30.84 million GPU hours. In contrast, Deepseek v3, with 671B parameters and trained on 14.8 trillion tokens, required approximately 2.788 million GPU hours, costing around $5.576 million. This indicates that Llama 3.1's training was more resource-intensive compared to Deepseek v3.",single_hop_specifc_query_synthesizer
How much did Deepseek v3 cost to train?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 cost approximately $5.576 million to train, based on a total of 2.788 million GPU hours at a rental price of $2 per GPU hour.",single_hop_specifc_query_synthesizer
How does the training cost and efficiency of Llama 3.1 compare to Deepseek v3 based on the provided context?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The training cost and efficiency of Llama 3.1 compared to Deepseek v3 shows significant differences. Llama 3.1, with 405B parameters and trained on 15 trillion tokens, reportedly required 30.84 million GPU hours. In contrast, Deepseek v3, which has 671B parameters and was trained on approximately 14.8 trillion tokens, required about 2.788 million GPU hours. The cost estimation for Deepseek v3, assuming a rental price of $2 per GPU hour, amounts to approximately $5.576 million. This indicates that Deepseek v3 is more efficient in terms of GPU hours and cost compared to Llama 3.1.",single_hop_specifc_query_synthesizer
What role did the Nvidia h800s play in the training of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Nvidia h800s were used extensively in the training of the Deepseek v3 model, with a total of 2,788,000 GPU hours required for its full training. This training was completed in less than two months using a cluster of 2,048 H800 GPUs, and the rental cost for these GPU hours amounted to approximately $5.576 million.",single_hop_specifc_query_synthesizer
What is the significance of the HAI-LLM framework in the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The HAI-LLM framework is significant in the Deepseek v3 model as it is part of the breakthrough engineering that contributes to the model's success. This custom framework, along with the use of MoE architecture and FP8 mixed precision training, enhances the model's capabilities, particularly in reasoning and math, allowing it to surpass other models like GPT-4 and Claude 3.5 Sonnet.",single_hop_specifc_query_synthesizer
What does MOE stand for in the context of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","In the context of the Deepseek v3 model, MOE stands for Mixture of Agents, which is an architectural feature of the model showcasing a 671B parameter structure with 37B active parameters per token.",single_hop_specifc_query_synthesizer
What role does FP8 play in the training of the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","FP8 is used in the Deepseek v3 model to achieve mixed precision training, which is part of the breakthrough engineering that contributes to the model's efficiency and performance.",single_hop_specifc_query_synthesizer
How many GPU hours were utilized on the Nvidia h800s for training the Deepseek v3 model?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model utilized a total of approximately 2,788,000 GPU hours on the Nvidia h800s cluster during its training.",single_hop_specifc_query_synthesizer
What are the key features and cost breakdown of the Deepseek v3 model in AI research?,"['Breakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) and 37B active parameters per token. It excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet, although Claude 3.5 Sonnet maintains a slight lead in writing and coding tasks. The model was pre-trained on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around $5.576 million. The training involved 180K H800 GPU hours per trillion tokens, completed in less than two months using a cluster of 2,048 H800 GPUs. The total GPU hours include 2,664K for pre-training, 119K for context length extension, and 5K for post-training, leading to a total of approximately 2.788M GPU hours.",single_hop_specifc_query_synthesizer
"What are the key factors that contributed to the efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs, and how does this compare to the training costs of other models?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs can be attributed to several key factors. Firstly, Deepseek employed a Mixture-of-Experts (MoE) architecture, which allows only 37B parameters to activate for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. Additionally, they implemented FP8 mixed precision training, which reduced memory usage and accelerated training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. Furthermore, Deepseek developed a custom training framework called HAI-LLM, which included optimizations such as the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations to avoid costly tensor parallelism. 

In terms of costs, Deepseek reported that the training of their model took approximately 2,788,000 GPU hours on the Nvidia H800s cluster, costing around $5.576 million, which reflects the rental cost for the GPU hours needed. This is notably efficient when compared to other models, such as the Llama 3.1, which required 30,840,000 GPU hours for training. The efficiency of Deepseek V3 is further highlighted by its ability to achieve high performance with significantly lower training costs and time, showcasing a breakthrough in AI model training methodologies.",multi_hop_specific_query_synthesizer
What are the key features of Deepseek v3 that contribute to its efficiency and how do they compare to the costs associated with its training?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 is notable for its efficiency due to several key features: it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B out of 671B parameters per token, significantly reducing compute requirements. Additionally, it utilizes FP8 mixed precision training, which cuts memory usage by up to 50% compared to traditional formats. The custom training framework, HAI-LLM, includes optimizations like the DualPipe algorithm for efficient pipeline parallelism. In terms of costs, Deepseek v3's training took approximately 2,788,000 GPU hours, costing around $5.576 million, which reflects the rental price of $2 per GPU hour. This cost is significantly lower than other models, showcasing Deepseek's breakthrough engineering in achieving high performance at a reduced expense.",multi_hop_specific_query_synthesizer
What are the key differences in training efficiency and architecture between Deepseek r1 and Deepseek v3?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases significant advancements over Deepseek r1 in terms of training efficiency and architecture. Deepseek v3 employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B, which greatly reduces compute requirements compared to dense models. Additionally, it utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a 45 times increase in training efficiency. In contrast, Deepseek r1 does not incorporate these advanced techniques, making Deepseek v3 a more efficient and powerful model.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency of Deepseek v3 in terms of training costs and architecture, and how does it compare to other models like Llama 3.1?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency of Deepseek v3 in training costs and architecture is attributed to several key factors. Firstly, it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. Additionally, Deepseek v3 utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The custom training framework, HAI-LLM, incorporates optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies without the drawbacks of traditional methods. 

In terms of training costs, Deepseek v3 was reported to require approximately 2,788,000 GPU hours, costing around $5.576 million based on a rental price of $2 per GPU hour. This is notably efficient when compared to the Llama 3.1 model, which reportedly required 30,840,000 GPU hours for training. The efficiency of Deepseek v3 is further highlighted by its ability to train on 14.8 trillion high-quality data tokens, showcasing its advanced engineering and optimization strategies.",multi_hop_specific_query_synthesizer
"What are the key features of the Deepseek V3 model that contribute to its efficiency in training, particularly in relation to its MoE architecture and the reported training costs?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model showcases several key features that contribute to its efficiency in training. Firstly, it employs a Mixture-of-Experts (MoE) architecture, which allows only 37 billion parameters to activate for each token out of a total of 671 billion parameters. This sparse activation significantly reduces compute requirements compared to dense models. Additionally, Deepseek implemented FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also utilizes a custom training framework called HAI-LLM, which includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. Regarding the reported training costs, Deepseek V3 was trained using approximately 2.788 million GPU hours, costing around $5.576 million, which reflects the efficiency of their training process and the effective use of resources.",multi_hop_specific_query_synthesizer
What are the key innovations in the Deepseek V3 model that contribute to its efficiency and how do these innovations compare to the training costs and performance metrics outlined in the context?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model showcases several key innovations that contribute to its efficiency. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B parameters, which significantly reduces compute requirements compared to dense models. Additionally, the model utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. Furthermore, Deepseek developed a custom training framework called HAI-LLM, which includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved cross-node communication. 

In terms of training costs, Deepseek V3 was trained using approximately 2,788,000 GPU hours on a cluster of 2,048 Nvidia H800 GPUs, costing around $5.576 million. This cost reflects the rental price of $2 per GPU hour and includes the pre-training stage, context length extension, and post-training phases. The efficiency of Deepseek V3 is highlighted by its ability to achieve these results with a fraction of the training and inference costs compared to competitors, making it a significant disruptor in the AI industry.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency of the Deepseek v3 model, particularly in relation to its MoE architecture and the reported training costs of approximately $5.5 million?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency of the Deepseek v3 model can be attributed to several key factors related to its MoE (Mixture of Experts) architecture and its training costs. Firstly, the model employs a MoE architecture that activates only 37B parameters for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. This sparse activation allows for more efficient processing. Additionally, Deepseek implemented FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. Furthermore, the custom training framework called HAI-LLM includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and load balancing strategies that improve performance without the drawbacks of traditional methods. The reported training cost of approximately $5.5 million reflects the rental cost for GPU hours needed to train the model, which was completed in less than two months using a data center of 2,048 Nvidia H800 GPUs, totaling around 2.788 million GPU hours.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do these compare to the training costs associated with its development?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B parameters, which significantly reduces compute requirements compared to dense models. Additionally, Deepseek v3 utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. 

In terms of training costs, Deepseek v3 was trained using a cluster of 2,048 Nvidia H800 GPUs over a period of less than two months, resulting in a total of approximately 2.788 million GPU hours. The estimated cost for this training, based on a rental price of $2 per GPU hour, amounts to around $5.576 million. This cost reflects the efficiency of the training process, as Deepseek v3 achieved its performance with significantly lower training and inference costs compared to its competitors.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do they compare to the Deepseek r1 model?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, FP8 mixed precision training, and a custom training framework called HAI-LLM. The MoE architecture allows only 37B parameters to activate for each token out of a total of 671B, significantly reducing compute requirements. The FP8 mixed precision training reduces memory usage by up to 50% compared to traditional formats, while the HAI-LLM framework optimizes training through efficient pipeline parallelism and memory management. In contrast, the Deepseek r1 model, while showing better or equal performance to competitors, does not incorporate these advanced techniques, which makes Deepseek v3 a more efficient and powerful model overall.",multi_hop_specific_query_synthesizer
"What are the training costs and GPU usage for the Deepseek V3 model, and how does it compare to the Nvidia H800s in terms of efficiency?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The training costs for the Deepseek V3 model amount to approximately $5.576 million, which reflects the rental cost for 2.788 million GPU hours using a cluster of 2,048 Nvidia H800 GPUs. This training was completed in less than two months. In terms of efficiency, Deepseek V3 achieved a significant reduction in compute requirements by employing a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters out of a total of 671B for each token. This sparse activation, along with the implementation of FP8 mixed precision training and a custom training framework called HAI-LLM, allowed Deepseek to train more efficiently compared to other models, such as Llama 3.1, which required 30.84 million GPU hours for training.",multi_hop_specific_query_synthesizer
"What are the key differences in training efficiency and cost between Deepseek r1 and Deepseek v3, and how do these models compare in terms of architecture and performance?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases significant advancements over Deepseek r1 in terms of training efficiency and cost. Deepseek v3 employs a Mixture-of-Experts (MoE) architecture with 671 billion parameters, where only 37 billion parameters are active for each token, leading to reduced compute requirements. In contrast, Deepseek r1 does not utilize this advanced architecture. The training of Deepseek v3 was completed in less than two months using 2,048 Nvidia H800 GPUs, costing approximately $5.576 million, while Deepseek r1's cost and efficiency details are not specified. Additionally, Deepseek v3 implements FP8 mixed precision training and a custom HAI-LLM framework, which further enhances its performance and efficiency, allowing it to excel in reasoning and math tasks, surpassing models like GPT-4 and Claude 3.5 Sonnet.",multi_hop_specific_query_synthesizer
How did Deepseek utilize Nvidia h800s to achieve its training efficiency and what were the associated costs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek utilized a data center of approximately 2,000 Nvidia h800 GPUs to train its model, Deepseek V3, achieving significant training efficiency. The training process took about two months and cost around $5.5 million, which reflects the rental cost for the GPU hours needed. The model architecture employed a Mixture-of-Experts (MoE) design, which allowed only 37B parameters to be active for each token out of a total of 671B parameters, significantly reducing compute requirements. Additionally, Deepseek implemented FP8 mixed precision training, which reduced memory usage and accelerated training, and developed a custom training framework called HAI-LLM to optimize performance further.",multi_hop_specific_query_synthesizer
What are the key advancements in Deepseek v3 that contribute to its efficiency and how do they compare to the reported training costs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases several key advancements that contribute to its efficiency. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B, which significantly reduces compute requirements compared to dense models. Additionally, it utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. Regarding the reported training costs, Deepseek v3 was trained using approximately 2,788,000 GPU hours on Nvidia H800 GPUs, costing around $5.576 million. This cost reflects the rental price of $2 per GPU hour and aligns with the efficiency gains achieved through its innovative architecture and training methods.",multi_hop_specific_query_synthesizer
What are the key innovations in the Deepseek V3 model that contribute to its efficiency and how do they relate to the Mixture-of-Experts (MoE) architecture and the reported training costs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model showcases several key innovations that contribute to its efficiency, particularly through its Mixture-of-Experts (MoE) architecture. This architecture allows only 37 billion parameters to activate for each token out of a total of 671 billion parameters, significantly reducing compute requirements compared to dense models. Additionally, Deepseek implemented FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. The model also employs a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. These innovations collectively enable Deepseek V3 to train efficiently, completing the process in less than two months with a total of approximately 2.788 million GPU hours, resulting in a reported training cost of around $5.576 million. This cost reflects the effective use of resources, showcasing how the MoE architecture and advanced training techniques contribute to both performance and cost efficiency.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency of Deepseek V3, and how does its training cost compare to its reported expenses?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency of Deepseek V3 is attributed to several key factors: it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B, significantly reducing compute requirements. Additionally, it utilizes FP8 mixed precision training, which reduces memory usage and accelerates training compared to higher precision formats. The custom training framework, HAI-LLM, includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations. Regarding training costs, Deepseek V3 reportedly required approximately 2,788,000 GPU hours, costing around $5.576 million, which reflects the rental cost for the GPU hours needed for training. This cost is efficient compared to other models, as it achieved significant results with a fraction of the training and inference costs.",multi_hop_specific_query_synthesizer
What are the key features of the Deepseek V3 model that utilize the MoE architecture and how do they contribute to its efficiency?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters. This sparse activation significantly reduces compute requirements compared to dense models. Key features that contribute to its efficiency include: 1. **FP8 Mixed Precision Training**: This reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. 2. **Load Balancing Strategy**: An auxiliary loss-free strategy for load balancing improves performance without the drawbacks of traditional methods. 3. **Custom Training Framework (HAI-LLM)**: This framework includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and memory optimizations to avoid costly tensor parallelism. These innovations collectively enhance the model's training efficiency and performance.",multi_hop_specific_query_synthesizer
"What are the training costs and GPU usage for the Deepseek V3 model, particularly in relation to the Nvidia h800s, and how does this compare to the reported efficiency claims?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The training costs for the Deepseek V3 model, which utilized a cluster of 2,048 Nvidia h800 GPUs, amounted to approximately $5.576 million. This cost reflects the rental price of $2 per GPU hour for a total of about 2.788 million GPU hours required for its full training. The model was trained on 14.8 trillion tokens, achieving this in less than two months. The reported efficiency claims suggest that Deepseek V3 was able to complete its training with significantly fewer GPU hours compared to other models, such as Llama 3.1, which required 30.84 million GPU hours. This efficiency is attributed to the use of a Mixture-of-Experts (MoE) architecture and FP8 mixed precision training, which allowed Deepseek to optimize its training process effectively.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do these compare to the reported training costs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B, which significantly reduces compute requirements compared to dense models. Additionally, Deepseek v3 utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. 

In terms of training costs, Deepseek v3 was reported to have a total training cost of approximately $5.576 million, which reflects the rental cost for the GPU hours needed to train the model. This cost was based on the use of 2,788,000 GPU hours on Nvidia H800 GPUs, completed in less than two months. The efficiency of the training process, combined with the advanced architecture and training techniques, positions Deepseek v3 as a significant player in the AI landscape.",multi_hop_specific_query_synthesizer
What is the significance of the MoE architecture in Deepseek v3 and how does it relate to the reported training costs of around $5.5 million?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The significance of the MoE (Mixture-of-Experts) architecture in Deepseek v3 lies in its ability to activate only 37B parameters for each token out of a total of 671B parameters, which significantly reduces compute requirements compared to dense models. This architecture allows for more efficient training, which is crucial given the reported training costs of around $5.5 million. The training was completed using a data center of 2,000 Nvidia H800 GPUs over a period of two months, achieving a total of approximately 2.788 million GPU hours. The cost estimation of $5.5 million reflects the rental price of $2 per GPU hour, demonstrating how the MoE architecture contributes to both performance and cost efficiency in training the model.",multi_hop_specific_query_synthesizer
What are the key innovations in Deepseek v3 that contribute to its efficiency and how do they compare to the training costs of similar models?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases several key innovations that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, FP8 mixed precision training, and a custom training framework called HAI-LLM. The MoE architecture allows only 37B parameters to activate for each token out of a total of 671B, significantly reducing compute requirements. The FP8 mixed precision training reduces memory usage by up to 50% compared to traditional formats, while the HAI-LLM framework optimizes training through efficient pipeline parallelism and memory management. In terms of training costs, Deepseek v3 was trained using approximately 2.788 million GPU hours at a cost of around $5.576 million, which is notably efficient compared to other models like Llama 3.1, which required 30.84 million GPU hours.",multi_hop_specific_query_synthesizer
"How much did Deepseek spend on training their model using Nvidia h800s, and what was the total GPU hours required?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek spent approximately $5.576 million on training their model using Nvidia h800s. The total GPU hours required for the training of Deepseek-V3 was about 2.788 million GPU hours, which included 2,664K GPU hours for pre-training, 119K GPU hours for context length extension, and 5K GPU hours for post-training.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do they compare to the Deepseek r1 model?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency, particularly its use of a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters out of a total of 671B for each token, significantly reducing compute requirements. Additionally, it employs FP8 mixed precision training, which reduces memory usage by up to 50% compared to traditional formats, and a custom training framework called HAI-LLM that optimizes pipeline parallelism and memory usage. In contrast, the Deepseek r1 model, while also demonstrating competitive performance, does not incorporate these advanced techniques to the same extent, making Deepseek v3 a more efficient and powerful model overall.",multi_hop_specific_query_synthesizer
What are the key features of the Deepseek v3 model that utilize the MoE architecture and how do they contribute to its efficiency?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters. This sparse activation significantly reduces compute requirements compared to dense models. Key features that contribute to its efficiency include the implementation of FP8 mixed precision training, which reduces memory usage and accelerates training, and a custom training framework called HAI-LLM that optimizes pipeline parallelism and memory usage. Additionally, the model uses Multi-head Latent Attention (MLA) to compress the Key-Value cache, further enhancing training efficiency.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency of Deepseek V3 in terms of training costs and architecture, and how does it compare to other models like Llama 3.1?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency of Deepseek V3 in training costs and architecture is attributed to several key factors. Firstly, it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. Additionally, Deepseek V3 utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The custom training framework, HAI-LLM, incorporates optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies without the drawbacks of traditional methods. 

In terms of training costs, Deepseek V3 was reported to require approximately 2,788,000 GPU hours, costing around $5.576 million based on a rental price of $2 per GPU hour. This is notably efficient when compared to the Llama 3.1 model, which reportedly required 30,840,000 GPU hours for training. The efficiency of Deepseek V3 is further highlighted by its ability to achieve high performance with significantly lower resource consumption, making it a standout in the AI landscape.",multi_hop_specific_query_synthesizer
What are the key advancements in Deepseek v3 that contribute to its efficiency and how do they compare to the training costs of similar models?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases several key advancements that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, FP8 mixed precision training, and a custom training framework called HAI-LLM. The MoE architecture allows only 37B parameters to activate for each token out of a total of 671B, significantly reducing compute requirements. The FP8 mixed precision training reduces memory usage by up to 50% compared to traditional formats, while the HAI-LLM framework optimizes training through efficient pipeline parallelism and memory management. In terms of training costs, Deepseek v3 was trained using approximately 2.788 million GPU hours, costing around $5.576 million. This is notably efficient compared to similar models, such as Llama 3.1, which required 30.84 million GPU hours for training.",multi_hop_specific_query_synthesizer
What are the key innovations in the Deepseek V3 model that contribute to its efficiency and how do they compare to the training costs reported?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model showcases several key innovations that contribute to its efficiency. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B parameters, which significantly reduces compute requirements compared to dense models. Additionally, Deepseek implemented FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. They also developed a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved communication kernels to fully utilize network bandwidth. Regarding training costs, Deepseek V3 was reported to have a total training cost of approximately $5.576 million, based on the rental price of $2 per GPU hour for the 2.788 million GPU hours required for its full training. This cost reflects the efficiency achieved through their innovative approaches, as they managed to train the model using a data center of 2,048 Nvidia H800 GPUs over a period of less than two months.",multi_hop_specific_query_synthesizer
"What are the key differences in training efficiency and cost between Deepseek r1 and Deepseek v3, and how do these models compare in terms of architecture and performance?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek r1 and Deepseek v3 differ significantly in their training efficiency and cost. Deepseek v3 showcases a Mixture-of-Experts (MoE) architecture with 671 billion parameters, where only 37 billion parameters are active for each token, leading to a substantial reduction in compute requirements. In contrast, while the specifics of Deepseek r1's architecture are not detailed, it is noted that Deepseek v3 achieved a training efficiency that is 45 times more efficient than previous models by utilizing 8-bit precision instead of 32-bit, compressing key value indices, and employing multi-token prediction. The training cost for Deepseek v3 was approximately $5.5 million, reflecting the rental cost for GPU hours, while Deepseek r1's cost is not specified. In terms of performance, Deepseek v3 excels at reasoning and math, surpassing models like GPT-4 and Claude 3.5 Sonnet, indicating a significant advancement in capabilities compared to its predecessor.",multi_hop_specific_query_synthesizer
"What are the key features of the Deepseek v3 model that utilize the MoE architecture, and how do they contribute to its efficiency and cost-effectiveness in training compared to other models?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters. This sparse activation significantly reduces compute requirements compared to dense models. Key features that contribute to its efficiency include: 1. **FP8 Mixed Precision Training**: This reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. 2. **Load Balancing Strategy**: Deepseek developed an auxiliary loss-free strategy for load balancing in the MoE architecture, improving performance without the drawbacks of traditional methods. 3. **Custom Training Framework (HAI-LLM)**: This framework includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and memory optimizations to avoid costly tensor parallelism. These innovations allowed Deepseek to train its model efficiently, completing the process in less than two months with a total cost of approximately $5.576 million, which is significantly lower than other models like Llama 3.1 that required much more GPU hours and resources.",multi_hop_specific_query_synthesizer
"What are the key features of the MOE architecture in Deepseek v3 that contribute to its efficiency, and how does it compare to traditional models?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The MOE (Mixture of Experts) architecture in Deepseek v3 is designed to enhance efficiency by activating only 37B parameters for each token out of a total of 671B parameters, which significantly reduces compute requirements compared to traditional dense models. This architecture allows for sparse activation, which is a key feature that contributes to the model's efficiency. Additionally, Deepseek v3 employs FP8 mixed precision training, which reduces memory usage and accelerates training, and a custom training framework called HAI-LLM that optimizes pipeline parallelism and memory usage. In comparison to traditional models, Deepseek v3's approach allows it to achieve better performance with lower resource consumption, making it a standout in the AI landscape.",multi_hop_specific_query_synthesizer
What are the key innovations in Deepseek v3 that contribute to its efficiency and how do they compare to the training costs and architecture of the model?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek v3 showcases several key innovations that contribute to its efficiency. Firstly, it employs a Mixture-of-Experts (MoE) architecture, activating only 37B parameters for each token out of a total of 671B parameters, which significantly reduces compute requirements compared to dense models. Additionally, Deepseek v3 utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also features a custom training framework called HAI-LLM, which includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved cross-node communication. In terms of training costs, Deepseek v3 was trained using approximately 2,788,000 GPU hours on a cluster of Nvidia H800 GPUs, costing around $5.576 million. This cost reflects the efficient training strategies employed, as the model was able to achieve its results with a fraction of the training and inference costs compared to other models, such as Llama 3.1, which required significantly more GPU hours for training.",multi_hop_specific_query_synthesizer
"What are the key differences in training efficiency and architecture between Deepseek r1 and Deepseek v3, and how do these advancements impact their performance in AI tasks?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek r1 and Deepseek v3 differ significantly in their training efficiency and architecture. Deepseek v3 employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. This architecture, combined with FP8 mixed precision training, allows Deepseek v3 to achieve a memory footprint reduction of up to 50% compared to traditional formats. Additionally, Deepseek v3 utilizes a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism. In contrast, while Deepseek r1 shows better or equal performance to competitors, it does not incorporate the same level of architectural advancements as v3. The improvements in Deepseek v3's training efficiency—such as using 8-bit instead of 32-bit for memory savings and achieving 93% compression ratios for key value indices—allow it to excel in reasoning and math tasks, surpassing models like GPT-4 and Claude 3.5 Sonnet. These advancements make Deepseek v3 a more powerful tool in the AI landscape, particularly for complex tasks.",multi_hop_specific_query_synthesizer
"What are the key differences in training efficiency and architecture between Deepseek r1 and Deepseek v3, and how do these advancements impact their performance in AI tasks?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek r1 and Deepseek v3 differ significantly in their training efficiency and architecture. Deepseek v3 employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters, leading to reduced compute requirements compared to dense models. This architecture, combined with FP8 mixed precision training, allows Deepseek v3 to achieve a memory footprint reduction of up to 50% compared to traditional formats. Additionally, Deepseek v3 utilizes a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. These advancements enable Deepseek v3 to excel at reasoning and math tasks, surpassing models like GPT-4 and Claude 3.5 Sonnet. In contrast, while Deepseek r1 shows competitive performance, it does not incorporate the same level of architectural innovation and efficiency improvements as Deepseek v3, which has led to its significant impact in the AI space.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs, and how does this compare to the training costs of other models?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs can be attributed to several key factors. Firstly, Deepseek employed a Mixture-of-Experts (MoE) architecture, which allows only 37B parameters to be active for each token out of a total of 671B parameters, significantly reducing compute requirements. Additionally, they implemented FP8 mixed precision training, which reduced memory usage and accelerated training compared to higher precision formats, achieving a memory footprint reduction of up to 50%. Furthermore, Deepseek developed a custom training framework called HAI-LLM, which included optimizations such as the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations to avoid costly tensor parallelism. 

In terms of costs, Deepseek reported that the total training for the V3 model required approximately 2.788 million GPU hours, costing around $5.576 million at a rental price of $2 per GPU hour. This is notably efficient compared to other models; for instance, the Llama 3.1 model, which has 405B parameters, reportedly required 30.84 million GPU hours for training. Thus, Deepseek's approach not only made training more efficient but also significantly reduced costs compared to its competitors.",multi_hop_specific_query_synthesizer
"What are the key features of the Deepseek V3 model that contribute to its efficiency in training, particularly in relation to its MoE architecture and the reported training costs?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model showcases several key features that contribute to its efficiency in training. Firstly, it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters. This sparse activation significantly reduces compute requirements compared to dense models. Additionally, the model utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. Furthermore, Deepseek developed a custom training framework called HAI-LLM, which includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. The reported training cost for Deepseek V3 was approximately $5.576 million, reflecting the efficient use of resources, as it required only 2.788 million GPU hours for its full training, completed in less than two months using a cluster of 2,048 Nvidia H800 GPUs.",multi_hop_specific_query_synthesizer
What were the key factors that contributed to the efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs can be attributed to several key factors. Firstly, Deepseek employed a Mixture-of-Experts (MoE) architecture, which allowed only 37B parameters to activate for each token out of a total of 671B parameters, significantly reducing compute requirements. Secondly, they implemented FP8 mixed precision training, which reduced memory usage and accelerated training, achieving a memory footprint reduction of up to 50% compared to traditional formats. Additionally, Deepseek developed a custom training framework called HAI-LLM, which included optimizations such as the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations to avoid costly tensor parallelism. The training process utilized a data center of approximately 2,000 Nvidia H800 GPUs over a period of two months, resulting in a total training cost of around $5.576 million, which reflects the rental cost for the GPU hours needed for training.",multi_hop_specific_query_synthesizer
What are the key architectural features and cost breakdown of the Deepseek V3 model that contribute to its efficiency in training compared to other models?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek V3 model showcases several key architectural features that contribute to its efficiency in training. It employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters are activated for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. Additionally, it utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also incorporates a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved cross-node communication. In terms of cost, the training of Deepseek V3 required approximately 2,788,000 GPU hours on a cluster of Nvidia H800 GPUs, costing around $5.576 million. This cost reflects the rental price of $2 per GPU hour and includes the pre-training stage, context length extension, and post-training phases.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do they compare to the training costs of Deepseek r1?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, FP8 mixed precision training, and a custom training framework called HAI-LLM. The MoE architecture allows only 37B parameters to activate for each token out of a total of 671B, significantly reducing compute requirements. The FP8 mixed precision training reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. Additionally, the HAI-LLM framework includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. In terms of training costs, Deepseek v3 was reported to cost approximately $5.576 million for its training, which involved 2,788,000 GPU hours. In contrast, the Deepseek r1 model, while also efficient, achieved its performance with a fraction of the training and inference costs, although specific figures for r1 are not detailed in the provided context.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do they compare to the Deepseek r1 model?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency, particularly its use of a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters out of a total of 671B for each token, significantly reducing compute requirements. Additionally, it employs FP8 mixed precision training, which reduces memory usage and accelerates training compared to higher precision formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism. In contrast, the Deepseek r1 model, while showing better or equal performance to competitors, does not incorporate these advanced techniques, making Deepseek v3 a more efficient and powerful model in the AI landscape.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do they compare to the Deepseek r1 model?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, FP8 mixed precision training, and a custom training framework called HAI-LLM. The MoE architecture allows only 37B parameters to activate for each token out of a total of 671B, significantly reducing compute requirements. The FP8 mixed precision training reduces memory usage by up to 50% compared to traditional formats, while the HAI-LLM framework optimizes training through efficient pipeline parallelism and memory management. In contrast, the Deepseek r1 model, while showing better or equal performance to competitors, achieved its results with a fraction of the training and inference cost but did not incorporate the same level of architectural advancements as seen in Deepseek v3.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency and cost-effectiveness of training the Deepseek v3 model using Nvidia h800s, and how does this compare to the training costs of other models?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency and cost-effectiveness of training the Deepseek v3 model using Nvidia h800s can be attributed to several key factors. Firstly, Deepseek employed a Mixture-of-Experts (MoE) architecture, which allows only 37B parameters to activate for each token out of a total of 671B parameters, significantly reducing compute requirements. Additionally, they implemented FP8 mixed precision training, which reduced memory usage and accelerated training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. Furthermore, Deepseek developed a custom training framework called HAI-LLM, which included optimizations such as the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations to avoid costly tensor parallelism. 

In terms of costs, Deepseek reported that the total training required approximately 2,788,000 GPU hours on the Nvidia h800s cluster, costing around $5.576 million, which reflects the rental cost for the GPU hours needed. This is notably efficient compared to other models, such as the Llama 3.1, which required 30,840,000 GPU hours for training, indicating that Deepseek's approach was significantly more efficient in both time and cost.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do they compare to the Deepseek r1 model in terms of training costs and architecture?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency, particularly its use of a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters out of a total of 671B for each token, significantly reducing compute requirements compared to dense models. Additionally, it employs FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. The custom training framework, HAI-LLM, includes optimizations such as the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. In terms of training costs, Deepseek v3 was trained using approximately 2.788 million GPU hours at a cost of around $5.576 million, while the earlier Deepseek r1 model achieved better or equal performance with a fraction of the training and inference costs, although specific figures for r1 are not detailed in the context. Overall, Deepseek v3's advancements in algorithmic efficiency and cost-effectiveness position it as a significant improvement over its predecessor.",multi_hop_specific_query_synthesizer
What are the key factors that contributed to the efficiency of Deepseek V3 in terms of training costs and architecture?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency of Deepseek V3 in terms of training costs and architecture can be attributed to several key factors. Firstly, it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B, significantly reducing compute requirements. Secondly, the implementation of FP8 mixed precision training reduces memory usage and accelerates training, cutting the memory footprint by up to 50% compared to traditional formats. Additionally, Deepseek V3 developed a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. These innovations allowed Deepseek V3 to achieve a training cost of approximately $5.576 million, reflecting a highly efficient use of resources.",multi_hop_specific_query_synthesizer
"What are the key factors that contributed to the efficiency of Deepseek V3 in terms of training costs and architecture, and how does it compare to other models?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency of Deepseek V3 in training costs and architecture is attributed to several key factors. Firstly, it employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters, significantly reducing compute requirements compared to dense models. Additionally, Deepseek V3 utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional FP16/FP32 formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved cross-node communication. In terms of costs, Deepseek V3 was trained using approximately 2,788,000 GPU hours on Nvidia H800 GPUs, costing around $5.576 million, which is notably efficient compared to other models like Llama 3.1, which required significantly more GPU hours for training.",multi_hop_specific_query_synthesizer
What are the key innovations in Deepseek V3 that contribute to its efficiency and how do they compare to the training costs and architecture of other models like Llama 3.1?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek V3 showcases several key innovations that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, FP8 mixed precision training, and a custom training framework called HAI-LLM. The MoE architecture allows only 37B parameters to activate for each token out of a total of 671B, significantly reducing compute requirements compared to dense models. The FP8 mixed precision training reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. The HAI-LLM framework includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. In terms of training costs, Deepseek V3 required approximately 2.788 million GPU hours, costing around $5.576 million, which is notably efficient compared to Llama 3.1, which reportedly required 30.84 million GPU hours for training. This efficiency highlights Deepseek V3's advancements in algorithmic improvements over hardware enhancements, setting it apart in the AI landscape.",multi_hop_specific_query_synthesizer
What are the key factors that contributed to the efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The efficiency and cost-effectiveness of training the Deepseek V3 model using Nvidia H800 GPUs can be attributed to several key factors. Firstly, Deepseek employed a Mixture-of-Experts (MoE) architecture, which allows only 37B parameters to activate for each token out of a total of 671B parameters, significantly reducing compute requirements. Secondly, they implemented FP8 mixed precision training, which reduced memory usage and accelerated training compared to higher precision formats, achieving a memory footprint reduction of up to 50%. Additionally, Deepseek developed a custom training framework called HAI-LLM, which included optimizations such as the DualPipe algorithm for efficient pipeline parallelism and careful memory optimizations to avoid costly tensor parallelism. The total training cost was approximately $5.576 million, reflecting the rental cost for 2.788 million GPU hours needed to train the model, which was completed in less than two months using a cluster of 2,048 Nvidia H800 GPUs.",multi_hop_specific_query_synthesizer
What are the key innovations in Deepseek V3 that contribute to its efficiency and how do they compare to the reported training costs?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","Deepseek V3 showcases several key innovations that contribute to its efficiency, including the use of a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters out of a total of 671B for each token, significantly reducing compute requirements. Additionally, it employs FP8 mixed precision training, which reduces memory usage and accelerates training compared to higher precision formats. The custom training framework, HAI-LLM, includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. Regarding training costs, Deepseek V3 was reported to have a total training cost of approximately $5.576 million, which reflects the rental cost for GPU hours needed to train the model, completed in less than two months using a cluster of 2,048 Nvidia H800 GPUs.",multi_hop_specific_query_synthesizer
What are the key features of the Deepseek v3 model that utilize the MoE architecture and how do they contribute to its efficiency in training?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B parameters. This sparse activation significantly reduces compute requirements compared to dense models. Key features that contribute to its efficiency include: 1. **Model Architecture**: The MoE architecture allows for better resource utilization by activating only a fraction of the total parameters. 2. **FP8 Mixed Precision Training**: This reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. 3. **Load Balancing Strategy**: An auxiliary loss-free strategy for load balancing improves performance without the drawbacks of traditional methods. 4. **Custom Training Framework (HAI-LLM)**: This framework includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and memory optimizations to avoid costly tensor parallelism. These features collectively enhance the training efficiency of the Deepseek v3 model.",multi_hop_specific_query_synthesizer
"What role did Nvidia H800 GPUs play in the training efficiency of Deepseek V3, and how does this relate to the reported training costs?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Nvidia H800 GPUs were crucial in the training efficiency of Deepseek V3, as the model was trained using a data center of approximately 2,000 H800 GPUs over a period of two months. This setup allowed Deepseek to achieve significant training efficiency, reportedly 45 times more efficient than previous models. The total training cost was around $5.5 million, which reflects the rental cost for the GPU hours needed to train Deepseek V3. The reported training breakdown indicated that the model required approximately 2.788 million GPU hours, leading to the estimated cost based on a rental price of $2 per GPU hour.",multi_hop_specific_query_synthesizer
"What were the training costs and GPU usage for the Deepseek V3 model, particularly in relation to the Nvidia H800s?","['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The training costs for the Deepseek V3 model amounted to approximately $5.576 million, which reflects the rental cost for the GPU hours needed to train the model. Deepseek utilized a cluster of 2,048 Nvidia H800 GPUs, completing the pre-training stage in less than two months. The total GPU hours required for the full training of Deepseek V3 were about 2.788 million, which included 2,664K GPU hours for pre-training, 119K GPU hours for context length extension, and 5K GPU hours for post-training.",multi_hop_specific_query_synthesizer
What are the key advancements in the Deepseek v3 model that contribute to its efficiency and how do these compare to the training costs associated with Deepseek r1?,"['<1-hop>\n\n<source name=""https://medium.com/@visithkumarapperuma/deepseek-v3-a-game-changer-in-a-i-heres-why-it-matters-75591957ca07""> author - Visith Kumarapperuma # Deepseek V3: A Game-Changer in A.I. Here’s Why It Matters Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek’s AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia. ## So what made Deepseek such a big impact to A.I. ? The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the “rental” cost for the GPU hours needed to train DeepSeek‑V3. It does not include: 1. The capital expenditure for owning the hardware. 2. Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data. ### Deepseek made training more efficient (45 times more efficient) - Use 8-bit instead of 32-bit to save memory. - Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios. - Do multi-token prediction instead of single-token prediction -> doubled inference speeds - The MOE model decomposes a big model into small models that can run on consumer-grade hardware. ## Summary of how Deepseek v3 was so efficient at training the frontier model 1. Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training. 2. FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy. 3. Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods. 4. Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism. ##', '<2-hop>\n\nBreakdown of the costs of the Deepseek v3 model Deepseek’s flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token - Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework. - Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet. - For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead. - Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million - the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. `So how true is the claim of $5.5 million, or is it another marketing trick?` 1. Underlying FLOP calculations Model Details: - Active Parameters: 37B (using FP8 precision) - FLOPs per token: Using the rule of thumb “6 FLOPs per parameter per token.” `37B×6 = 222B FLOPs per token` - Total Training Tokens: Approximately 14.8 trillion tokens - Total FLOPs required: `222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs` ### GPU FLOP Capacity (H800/H100): An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) `3.3×10²⁴ / 3.958×10¹⁵ \u200b≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour` Note: This “perfect efficiency” scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: `Using the same math: 3.64×10²⁵ FLOPs required` Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage: - Per Trillion Tokens: 180K H800 GPU hours - Overall Pre‑training: Total of 2,664K GPU hours - This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension: - Additional 119K GPU hours Post‑training: - An extra 5K GPU hours Total GPU Hours: `2,664 K+119 K+5 K≈2.788M GPU hours` 4. Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: `2.788M GPU hours×$2/hour≈$5.576 million` as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M. 5. Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours ### Cost (at $2 per GPU hour): ~$5.576 million']","The Deepseek v3 model showcases several key advancements that contribute to its efficiency. It employs a Mixture-of-Experts (MoE) architecture, which activates only 37B parameters for each token out of a total of 671B, significantly reducing compute requirements compared to dense models. Additionally, it utilizes FP8 mixed precision training, which reduces memory usage and accelerates training, achieving a memory footprint reduction of up to 50% compared to traditional formats. The model also features a custom training framework called HAI-LLM, which includes optimizations like the DualPipe algorithm for efficient pipeline parallelism and improved load balancing strategies. 

In terms of training costs, Deepseek v3 was trained using approximately 2,788,000 GPU hours on a cluster of Nvidia H800 GPUs, costing around $5.576 million. This is a significant achievement considering the efficiency improvements made in the training process. In contrast, the Deepseek r1 model, while also efficient, does not have the same level of detailed cost breakdown or the extensive training optimizations that v3 has implemented. The advancements in v3, particularly in algorithmic improvements rather than hardware enhancements, have positioned it as a leader in the AI space.",multi_hop_specific_query_synthesizer
